
# ğŸŒ³ Decision Tree ve Random Forest AlgoritmalarÄ±

Makine Ã¶ÄŸrenmesinde sÄ±nÄ±flandÄ±rma ve regresyon problemlerinde yaygÄ±n olarak kullanÄ±lan iki algoritma: **Decision Tree (Karar AÄŸacÄ±)** ve **Random Forest (Rastgele Orman)**. Bu iki algoritma, Ã¶zellikle yorumlanabilirlik ve doÄŸruluk aÃ§Ä±sÄ±ndan sÄ±klÄ±kla karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r. Bu dokÃ¼manda her iki algoritmanÄ±n temel prensipleri, avantajlarÄ± ve karÅŸÄ±laÅŸtÄ±rmalarÄ± ele alÄ±nacaktÄ±r.

---

## ğŸ§  Decision Tree (Karar AÄŸacÄ±)

### ğŸ“Œ TanÄ±m
Karar aÄŸacÄ±, verileri **aÄŸaÃ§ yapÄ±sÄ±nda** bÃ¶len denetimli bir makine Ã¶ÄŸrenimi algoritmasÄ±dÄ±r. DÃ¼ÄŸÃ¼mlerde veriler belirli Ã¶zelliklere gÃ¶re bÃ¶lÃ¼nÃ¼r ve yapraklarda tahmin yapÄ±lÄ±r.


### âš™ï¸ Ã‡alÄ±ÅŸma MantÄ±ÄŸÄ±
- En iyi Ã¶zelliÄŸi seÃ§mek iÃ§in genellikle **Gini Impurity** veya **Entropy** kullanÄ±lÄ±r.
- Her bÃ¶lÃ¼nme, veri kÃ¼mesini daha homojen alt kÃ¼melere ayÄ±rmayÄ± hedefler.
- AÄŸaÃ§ yapÄ±sÄ± **kÃ¶k dÃ¼ÄŸÃ¼m**, **karar dÃ¼ÄŸÃ¼mleri** ve **yaprak dÃ¼ÄŸÃ¼mlerden** oluÅŸur.

### âœ… AvantajlarÄ±
- Kolay anlaÅŸÄ±lÄ±r ve gÃ¶rselleÅŸtirilebilir.
- Kategorik ve sayÄ±sal verilerle Ã§alÄ±ÅŸabilir.
- Ã–zellik Ã¶lÃ§ekleme gerekmez.

### âŒ DezavantajlarÄ±
- AÅŸÄ±rÄ± Ã¶ÄŸrenme (overfitting) eÄŸilimi yÃ¼ksektir.
- KÃ¼Ã§Ã¼k veri deÄŸiÅŸikliklerine duyarlÄ±dÄ±r.

### ğŸ” Ã–rnek KullanÄ±m
```python
from sklearn.tree import DecisionTreeClassifier

model = DecisionTreeClassifier()
model.fit(X_train, y_train)
predictions = model.predict(X_test)
```

---

## ğŸŒ² Random Forest (Rastgele Orman)

### ğŸ“Œ TanÄ±m
Random Forest, birÃ§ok karar aÄŸacÄ±ndan oluÅŸan **ensemble (topluluk) Ã¶ÄŸrenme yÃ¶ntemidir**. Her bir aÄŸaÃ§ rastgele veri alt kÃ¼meleriyle eÄŸitilir ve nihai karar, tÃ¼m aÄŸaÃ§larÄ±n oy birliÄŸiyle veya ortalamasÄ±yla verilir.


### âš™ï¸ Ã‡alÄ±ÅŸma MantÄ±ÄŸÄ±
- Bootstrap yÃ¶ntemi ile veri alt kÃ¼meleri oluÅŸturulur.
- Her aÄŸaÃ§ farklÄ± Ã¶zellik kombinasyonlarÄ±yla eÄŸitilir.
- SonuÃ§lar birleÅŸtirilerek daha doÄŸru tahmin yapÄ±lÄ±r.

### âœ… AvantajlarÄ±
- AÅŸÄ±rÄ± Ã¶ÄŸrenmeyi azaltÄ±r.
- Daha doÄŸru ve kararlÄ± sonuÃ§lar verir.
- Outlierâ€™lara ve gÃ¼rÃ¼ltÃ¼ye karÅŸÄ± daha dayanÄ±klÄ±dÄ±r.

### âŒ DezavantajlarÄ±
- EÄŸitilmesi daha uzun sÃ¼rebilir.
- YorumlanmasÄ± zordur (karar aÄŸacÄ± kadar anlaÅŸÄ±lÄ±r deÄŸildir).

### ğŸ” Ã–rnek KullanÄ±m
```python
from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier(n_estimators=100)
model.fit(X_train, y_train)
predictions = model.predict(X_test)
```

---

## âš–ï¸ KarÅŸÄ±laÅŸtÄ±rma Tablosu

| Ã–zellik                | Decision Tree       | Random Forest         |
|------------------------|---------------------|------------------------|
| HÄ±zlÄ± EÄŸitim           | âœ…                  | âŒ                    |
| AÅŸÄ±rÄ± Ã–ÄŸrenme          | âŒ (eÄŸilimli)        | âœ… (azaltÄ±lmÄ±ÅŸ)       |
| Yorumlanabilirlik      | âœ…                  | âŒ                    |
| DoÄŸruluk               | Orta                | YÃ¼ksek                |
| GÃ¼rÃ¼ltÃ¼ye DayanÄ±klÄ±lÄ±k | DÃ¼ÅŸÃ¼k               | YÃ¼ksek                |



## âœï¸ Notlar
- Her zaman model performansÄ±nÄ± Ã§apraz doÄŸrulama (cross-validation) ile deÄŸerlendirin.
- Ã–zellik Ã¶nemi (feature importance) iÃ§in Random Forest oldukÃ§a kullanÄ±ÅŸlÄ±dÄ±r.
